{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff84e7-fa56-424f-b303-8f369a0b6d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from transformers import BertModel, BertTokenizerFast, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from tqdm import tqdm \n",
    "from evaluate import load\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d3003-b40c-4c29-bdf1-6e0e46dcba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_test_data(file_path):\n",
    "    with open(file_path,'rb') as file:\n",
    "        data=json.load(file)\n",
    "    context=[]\n",
    "    questions=[]\n",
    "    answers = []\n",
    "    no_questions= 0\n",
    "\n",
    "    for line in data['data']:\n",
    "        for para in line['paragraphs']:\n",
    "            context1 = para['context']\n",
    "            for q_a in para['qas']:\n",
    "                q = q_a['question']\n",
    "                #print(q)\n",
    "                no_questions = no_questions +1\n",
    "                for ans in q_a['answers']:\n",
    "                    context.append(context1.lower())\n",
    "                    questions.append(q.lower())\n",
    "                    answers.append(ans)\n",
    "\n",
    "\n",
    "\n",
    "    return context,questions,no_questions,answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c651ea43-e18f-4bd0-82e2-be44f43d6707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_answer_train(idx):\n",
    "    start = 0\n",
    "    end = 0\n",
    "    answer_encoding= tokenizer(train_answers[idx]['text'],  max_length = MAX_LENGTH, truncation=True, padding=True)\n",
    "    for ans in range( len(train_encoding['input_ids'][idx]) -  len(answer_encoding['input_ids']) ): #len(train_encodings_fast['input_ids'][0])):\n",
    "        match = True\n",
    "        for i in range(1,len(answer_encoding['input_ids']) - 1):\n",
    "            if (answer_encoding['input_ids'][i] != train_encoding['input_ids'][idx][ans + i]):\n",
    "                match = False\n",
    "                break\n",
    "            if match:\n",
    "                start = ans+1\n",
    "                end = ans+i+1\n",
    "                break\n",
    "    return(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6046d56d-e92d-4828-967a-d069aa680011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_answer_test(idx):\n",
    "    start = 0\n",
    "    end = 0\n",
    "    answer_encoding= tokenizer(test_answers[idx]['text'],  max_length = MAX_LENGTH, truncation=True, padding=True)\n",
    "    for ans in range( len(test_encoding['input_ids'][idx]) -  len(answer_encoding['input_ids']) ): #len(train_encodings_fast['input_ids'][0])):\n",
    "        match = True\n",
    "        for i in range(1,len(answer_encoding['input_ids']) - 1):\n",
    "            if (answer_encoding['input_ids'][i] != test_encoding['input_ids'][idx][ans + i]):\n",
    "                match = False\n",
    "                break\n",
    "            if match:\n",
    "                start = ans+1\n",
    "                end = ans+i+1\n",
    "                break\n",
    "    return(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed14fca4-d685-48c4-821a-57975fcf679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_start_end_train(train_encoding):\n",
    "    start_pos=[]\n",
    "    end_pos=[]\n",
    "    ctr = 0\n",
    "    for i in range(len(train_encoding['input_ids'])):\n",
    "        start,end = process_answer_train(i)\n",
    "        start_pos.append(start)\n",
    "        end_pos.append(end)\n",
    "        if start==0:\n",
    "            ctr = ctr+1\n",
    "    return start_pos,end_pos,ctr\n",
    "\n",
    "\n",
    "def process_start_end_test(test_encoding):\n",
    "    start_pos=[]\n",
    "    end_pos=[]\n",
    "    ctr = 0\n",
    "    for i in range(len(test_encoding['input_ids'])):\n",
    "        start,end = process_answer_test(i)\n",
    "        start_pos.append(start)\n",
    "        end_pos.append(end)\n",
    "        if start==0:\n",
    "            ctr = ctr+1\n",
    "    return start_pos,end_pos,ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d94127-8312-4835-aee8-13677264fefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    \n",
    "    def __getitem__(self, index) :\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.encodings['input_ids'][index]),\n",
    "            'token_type_ids': torch.tensor(self.encodings['token_type_ids'][index]),\n",
    "            'attention_mask': torch.tensor(self.encodings['attention_mask'][index]),\n",
    "            'start_positions': torch.tensor(self.encodings['start_positions'][index]),\n",
    "            'end_positions': torch.tensor(self.encodings['end_positions'][index])\n",
    "        }\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd2661f-e21e-404f-957d-f6fb4f67d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERT_Model, self).__init__()\n",
    "        self.bert = model_bert\n",
    "        self.drop_out = nn.Dropout(0.1)\n",
    "        self.l1 = nn.Linear(768 * 2, 768 * 2)\n",
    "        self.l2 = nn.Linear(768 * 2, 2)\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            self.drop_out,\n",
    "            self.l1,\n",
    "            nn.LeakyReLU(),\n",
    "            self.l2 \n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        model_output = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, output_hidden_states=True)\n",
    "        hidden_states = model_output[2]\n",
    "        out = torch.cat((hidden_states[-1], hidden_states[-3]), dim=-1)  # taking Start logits from last BERT layer, End Logits from third to last layer\n",
    "        logits = self.linear_relu_stack(out)\n",
    "        \n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        \n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "\n",
    "        return start_logits, end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606d031-8780-4825-b19b-4b5f8085d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(start1, end1, start_pos, end_pos):\n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "    start_loss = loss_fct(start1, start_pos)\n",
    "    end_loss = loss_fct(end1, end_pos)\n",
    "    total_loss = (start_loss + end_loss)/2\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac766d-e2f7-421a-b8a1-170870ae5d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLLLoss_function(start1, end1, start_pos, end_pos, gamma):\n",
    "    \n",
    "    #calculate Probabilities by applying Softmax to the Start and End Logits. Then get 1 - probabilities\n",
    "    smax = nn.Softmax(dim=1)\n",
    "    probs_start = smax(start1)\n",
    "    inv_probs_start = 1 - probs_start\n",
    "    probs_end = smax(end1)\n",
    "    inv_probs_end = 1 - probs_end\n",
    "    \n",
    "    #get log of probabilities. Note: NLLLoss required log probabilities. This is the Natural Log (Log base e)\n",
    "    lsmax = nn.LogSoftmax(dim=1)\n",
    "    log_probs_start = lsmax(start1)\n",
    "    log_probs_end = lsmax(end1)\n",
    "    \n",
    "    nll = nn.NLLLoss()\n",
    "    \n",
    "    fl_start = nll(torch.pow(inv_probs_start, gamma)* log_probs_start, start_pos)\n",
    "    fl_end = nll(torch.pow(inv_probs_end, gamma)*log_probs_end, end_pos)\n",
    "    \n",
    "    #return mean of the Loss for the start and end logits\n",
    "    return ((fl_start + fl_end)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57283c-44d2-4bf4-a58c-9e57b9611833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, loader, epoch):\n",
    "    model.train()\n",
    "    optimizer = AdamW(model.parameters(), lr = 2e-5, weight_decay=2e-2)\n",
    "    schedular = ExponentialLR(optimizer,gamma=0.9)\n",
    "    total_acc = []\n",
    "    total_loss = []\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    acc = []\n",
    "    ctr = 0\n",
    "    batch_tracker = 0\n",
    "    for batch in tqdm(loader, desc = 'Running Epoch '):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        output_start, output_end = model(input_ids=input_ids, \n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids)\n",
    "        \n",
    "        loss = NLLLoss_function(output_start, output_end, start_positions, end_positions,1) \n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        start_pred = torch.argmax(output_start, dim=1)\n",
    "        end_pred = torch.argmax(output_end, dim=1)\n",
    "            \n",
    "        acc.append(((start_pred == start_positions).sum()/len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_positions).sum()/len(end_pred)).item())\n",
    "\n",
    "        batch_tracker = batch_tracker + 1\n",
    "        if batch_tracker==250 and epoch==1:\n",
    "            total_acc.append(sum(acc)/len(acc))\n",
    "            loss_avg = sum(losses)/len(losses)\n",
    "            total_loss.append(loss_avg)\n",
    "            batch_tracker = 0\n",
    "    schedular.step()\n",
    "    ret_acc = sum(acc)/len(acc)\n",
    "    ret_loss = sum(losses)/len(losses)\n",
    "    \n",
    "    return(ret_acc, ret_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff408636-f620-49ed-8434-4e29a90bc576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    acc = []\n",
    "    ctr = 0\n",
    "    answer_list=[]\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc = 'Running Evaluation'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            start_true = batch['start_positions'].to(device)\n",
    "            end_true = batch['end_positions'].to(device)\n",
    "            \n",
    "            output_start, output_end = model(input_ids=input_ids, attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "            start_pred = torch.argmax(output_start)\n",
    "            end_pred = torch.argmax(output_end)\n",
    "            answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][start_pred:end_pred]))\n",
    "            tanswer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][start_true[0]:end_true[0]]))\n",
    "            answer_list.append([answer,tanswer])\n",
    "    return answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4006e-d30a-4159-8440-c121c62c1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_wer():\n",
    "    wer_eval = load(\"wer\")\n",
    "    epochs = 3\n",
    "    model.to(device)\n",
    "\n",
    "    list_wer=[]\n",
    "\n",
    "    for e in range(epochs):\n",
    "        train_accuracy, train_loss = training(model,loader_train,e+1)\n",
    "        print(f\"Train Accuracy: {train_accuracy}      Train Loss: {train_loss}\")\n",
    "        answer_list = evaluate_model(model, loader_test)\n",
    "        pred_answers=[]\n",
    "        true_answers=[]\n",
    "        for i in range(len(answer_list)):\n",
    "            if(len(answer_list[i][0])==0):\n",
    "                answer_list[i][0]=\"$\"\n",
    "            if(len(answer_list[i][1])==0):\n",
    "                answer_list[i][1]=\"$\"\n",
    "            pred_answers.append(answer_list[i][0])\n",
    "            true_answers.append(answer_list[i][1])\n",
    "\n",
    "        wer_score = wer_eval.compute(predictions=pred_answers, references=true_answers)\n",
    "        list_wer.append(wer_score)\n",
    "    print(list_wer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef56d734-b5cd-4347-a3ab-2a0d4bb4bd54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bb0844-6582-4ac6-9372-0488b8710f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "context_train, train_questions, train_no_ques, train_answers = process_train_test_data('spoken_train-v1.1.json')\n",
    "context_test, test_questions, test_no_ques, test_answers = process_train_test_data('spoken_test-v1.1.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9414c66-a68f-4af4-99b7-4849cbcfada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "print(tokenizer)\n",
    "MAX_LENGTH = 250\n",
    "\n",
    "train_encoding = tokenizer(train_questions,context_train,max_length=MAX_LENGTH,truncation=True,padding=True)\n",
    "test_encoding = tokenizer(test_questions,context_test,max_length = MAX_LENGTH,truncation = True,padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ff0650-d63b-4216-89bb-3975c14e7f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_position_train,end_position_train,ctr1 = process_start_end_train(train_encoding)\n",
    "\n",
    "train_encoding.update({'start_positions': start_position_train, 'end_positions': end_position_train})\n",
    "\n",
    "print(ctr1)\n",
    "\n",
    "start_position_test,end_position_test,ctr2 = process_start_end_test(test_encoding)\n",
    "\n",
    "test_encoding.update({'start_positions': start_position_test, 'end_positions': end_position_test})\n",
    "\n",
    "print(ctr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f3358f-45a2-4625-97e9-939e390f109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_train = Input(train_encoding)\n",
    "dataset_test = Input(test_encoding)\n",
    "loader_train = DataLoader(dataset_train)\n",
    "loader_test = DataLoader(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f2f60a-8169-49e5-865a-d08c8cdede88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model = BERT_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833c36ab-fd90-4e36-b587-0f56c5bb8578",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    evaluate_wer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831a2c97-696c-4877-9f80-25cc438544cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
