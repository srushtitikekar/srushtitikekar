{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da9ebbe2-6d38-4701-afea-1979ea109917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5854c3b1-ed60-45f7-8492-4cb01f413d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 128\n",
    "latent_dim = 100\n",
    "img_size = 64\n",
    "channels = 1\n",
    "sample_interval = 400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7499591-07e7-4c48-9d0f-91e760327482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "                               transforms.Resize(img_size),\n",
    "                               transforms.CenterCrop(img_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ])\n",
    "trainset = dset.CIFAR10(root='./data', train=True,\n",
    "                                        download=True,transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4958a96a-7614-47a0-b2ff-bc78b1e6233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1f9dd62-456d-46a0-a462-8ee8c31b25c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebb4b01f-9d15-4ebf-92f2-f775371fed37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c647a247-b735-4871-bcc7-3d7dd0ec0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_size, img_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_size = latent_size\n",
    "        self.img_shape = img_shape\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_size, 128, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, img_shape[0], 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = z.view(z.size(0), self.latent_size, 1, 1)\n",
    "        img = self.model(z)\n",
    "        return img\n",
    "\n",
    "# Define the discriminator architecture\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.img_shape = img_shape\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(img_shape[0], 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 1, 4, 1, 0, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        validity = self.model(img)\n",
    "        return validity.view(-1)\n",
    "\n",
    "\n",
    "def wasserstein_loss(real_scores, fake_scores):\n",
    "    return -torch.mean(real_scores) + torch.mean(fake_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fee60ec-c66b-4d03-b286-9812f25c3adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def train_wgan(generator, discriminator, dataloader, num_epochs, batch_size, latent_size, lr, clip_value):\n",
    "    G_losses=[]\n",
    "    img_list=[]\n",
    "    D_losses=[]\n",
    "    cuda = True if torch.cuda.is_available() else False\n",
    "    Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    " \n",
    "    optimizer_G = optim.RMSprop(generator.parameters(), lr=lr)\n",
    "    optimizer_D = optim.RMSprop(discriminator.parameters(), lr=lr)\n",
    "    iters = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (imgs, _) in enumerate(train_loader):\n",
    "            # Sample a batch of noise vectors for generator input\n",
    "            z = Variable(Tensor(batch_size, latent_size).normal_())\n",
    "\n",
    "            # Generate a batch of fake images\n",
    "            gen_imgs = generator(z)\n",
    "\n",
    "            # Clip the discriminator weights to enforce Lipschitz continuity\n",
    "            for p in discriminator.parameters():\n",
    "                p.data.clamp_(-clip_value, clip_value)\n",
    "\n",
    "            # Train the discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            # Compute discriminator output on real and fake images\n",
    "            real_scores = discriminator(imgs.type(Tensor))\n",
    "            fake_scores = discriminator(gen_imgs.detach())\n",
    "\n",
    "            # Compute Wasserstein distance loss and backpropagate\n",
    "            d_loss = wasserstein_loss(real_scores, fake_scores)\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "            img_list.append(vutils.make_grid(gen_imgs, padding=2, normalize=True))\n",
    "            vutils.save_image(gen_imgs,\n",
    "                '%s/results_epoch_%03d.png' % ('WGAN/', epoch))\n",
    "            vutils.save_image(imgs,\n",
    "                '%s/real_results_epoch_%03d.png' % ('WGAN/', epoch))\n",
    "            # Train the generator\n",
    "            if i % 100 == 0:\n",
    "                optimizer_G.zero_grad()\n",
    "\n",
    "                # Generate a new batch of fake images\n",
    "                gen_imgs = generator(z)\n",
    "\n",
    "                # Compute discriminator output on new fake images\n",
    "                fake_scores = discriminator(gen_imgs)\n",
    "                \n",
    "                # Compute generator loss and backpropagate\n",
    "                g_loss = -torch.mean(fake_scores)\n",
    "                g_loss.backward()\n",
    "                optimizer_G.step()\n",
    "                print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\" % (epoch, num_epochs, i, len(dataloader), d_loss.item(), g_loss.item()))\n",
    "                vutils.save_image(gen_imgs,\n",
    "                '%s/results_epoch_%03d.png' % ('WGAN/', epoch))\n",
    "                vutils.save_image(imgs,\n",
    "                '%s/real_results_epoch_%03d.png' % ('WGAN/', epoch))\n",
    "            G_losses.append(g_loss.item())\n",
    "            D_losses.append(d_loss.item())   \n",
    "           \n",
    "            iters += 1\n",
    "\n",
    "    plot_it(G_losses,D_losses)\n",
    "    images(img_list)\n",
    "    #fig = plt.figure(figsize=(8,8))\n",
    "    #plt.axis(\"off\")\n",
    "    #ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "    #ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "    #HTML(ani.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6505d7-cd0e-4669-9d81-73c07188cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "426a5eb4-206c-4f44-a0c7-b9277afefca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "netG = Generator(latent_dim, img_shape).to('cuda')\n",
    "netD = Discriminator(img_shape).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58eb8c52-d46f-46c6-bdd3-a832d4c0591a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (model): Sequential(\n",
       "    (0): ConvTranspose2d(100, 128, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32db9d23-3ade-49d4-b294-0504e779be42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc515533-eedc-4207-8c42-80ebc51da4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_it(g_loss,d_loss):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "    plt.plot(g_loss,label=\"G\")\n",
    "    plt.plot(d_loss,label=\"D\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9703309c-a174-41eb-88a4-ff3b642d644b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be07338-2940-45d3-8dba-0a2083ef1466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/5] [Batch 0/391] [D loss: 0.000000] [G loss: 2.745760]\n",
      "[Epoch 0/5] [Batch 100/391] [D loss: -0.000587] [G loss: 0.128273]\n",
      "[Epoch 0/5] [Batch 200/391] [D loss: -0.000604] [G loss: 0.089055]\n",
      "[Epoch 0/5] [Batch 300/391] [D loss: -0.000623] [G loss: 0.080351]\n"
     ]
    }
   ],
   "source": [
    "train_wgan(netG, netD, train_loader, n_epochs, batch_size,latent_dim, 0.01, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5486b86c-95af-4f36-a785-f36009148a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_it(GL,DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0a957a5-583e-4cab-820a-380357838884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_it(g_loss,d_loss):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "    plt.plot(g_loss,label=\"G\")\n",
    "    plt.plot(d_loss,label=\"D\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc95fc7c-d810-480d-8bd8-74c1f3580a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e51f39-ff1a-40d0-9d75-5bf530fdb436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06d5b9e-0013-4d14-93b3-ff491a6710d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c53100-c17c-473e-8fdb-038d1f60060f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b258185-aab9-47c3-b749-dd5a54ba296c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
